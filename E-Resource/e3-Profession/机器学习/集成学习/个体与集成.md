
**集成学习(Ensemble Learning)**通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统(Multi-classifier System)、基于委员会的学习(Committee-based Learning）等。

**集成学习结构**：先产生一组**个体学习器(individuallearner)**，再用某种策略将它们结合起来。个体学习器通常由一个现有的学习算法从训练数据产生，例如C4.5决策树算法、BP神经网络算法等。

![[集成学习示意图.png#pic_center|400]]

- **同质集成(homogeneous ensemble)**：集成中只包含同种类型的个体学习器。
- **基学习器(base learner)**：同质集成中的个体学习器。
- **基学习算法(（baselearning algorithm)**：基学习器相应的学习算法。
- **异质集成(heterogenous ensemble)**: 集成包含不同类型的个体学习器。
- **组件学习器(（component learner))**:异质集成中的个体学习器。

==集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能==，这对**弱学习器(weak learner)** 尤为明显。因此集成学习的很多理精度论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器。

> [!NOTE]+ 弱学习器
> 弱学习器： 泛化性能略优于随机猜测的学习器。如弱分类器的分类准确率在60%-80%。反之，如果分类精度90%以上，则是强分类器。

但需注意的是，虽然从论上来说使用弱学习器集成足以获得好的性能，但在实践中出于种种考虑，例如希望使用较少的个体学习器，或是重用关于常见学习器的一些经验等，人们往往会使用比较强的学习器。==要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏，并且要有“多样性”（diversity)，即学习器间具有差异。==

根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即**个体学习器间存在强依赖关系、必须串行生成的序列化方法**，以及**个体学习器间不存在强依赖关系、可同时生成的并行化方法**；前者的代表是**Boosting**，后者的代表是**Bagging** 和 **“随机森林”(RandomForest) ** .


考虑二分类问题$y\in \{ -1, +1\}$和真实函数$f$，假定基分类器的错误率为$\epsilon$，即对每个分类器$h_i$有：

$$
P\left(h_{i}(\boldsymbol{x}) \neq f(\boldsymbol{x})\right)=\epsilon
\tag{1}
$$



**[解析]：**$h_{i}(\boldsymbol{x})$是编号为$i$的基分类器给$x$的预测标记，$f(\boldsymbol{x})$是$x$的真实标记，它们之间不一致的概率记为$\epsilon$。

假设集成通过简单投票法结合$T$个基分类器，若有超过半数的基分类器正确，则集成分类就正确：

$$
H(\boldsymbol{x})=\operatorname{sign}\left(\sum_{i=1}^{T} h_{i}(\boldsymbol{x})\right)
\tag{2}
$$

**[解析]：**$h_i(\boldsymbol{x})$当把$\boldsymbol{x}$分成1时，$h_i(\boldsymbol{x})=1$，否则$h_i(\boldsymbol{x})=-1$。各个基分类器$h_i$的分类结果求和之后数字的正、负或0，代表投票法产生的结果，即“少数服从多数”，符号函数$\operatorname{sign}$，将正数变成1，负数变成-1，0仍然是0，所以$H(\boldsymbol{x})$是由投票法产生的分类结果。

**假设基分类器的错误率相互独立**，则由**Hoefding不等式**可知，集成的错误率为:

$$
\begin{aligned}
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) &=\sum_{k=0}^{\lfloor T / 2\rfloor} \left( \begin{array}{c}{T} \\ {k}\end{array}\right)(1-\epsilon)^{k} \epsilon^{T-k} \\ & \leqslant \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right) 
\end{aligned}
\tag{3}
$$

**[公式$(3)$推导]**：由基分类器相互独立，设随机变量$X$为$T$个基分类器分类正确的次数，则$\mathrm{X}$服从二项分布：$\mathrm{X} \sim \mathcal{B}(\mathrm{T}, 1-\mathrm{\epsilon})$，设$x_i$为每一个分类器分类正确的次数，则$x_i\sim \mathcal{B}(1, 1-\mathrm{\epsilon})(i=1，2，3，...，\mathrm{T})$，那么有

$$
\begin{aligned}
\mathrm{X}&=\sum_{i=1}^{\mathrm{T}} x_i\\
\mathbb{E}(X)&=\sum_{i=1}^{\mathrm{T}}\mathbb{E}(x_i)=(1-\epsilon)T
\end{aligned}
$$

则：

$$
\begin{aligned} P(H(x) \neq f(x))=& P(X \leq\lfloor T / 2\rfloor) \\ & \leqslant P(X \leq T / 2)
\\ & =P\left[X-(1-\epsilon) T \leqslant \frac{T}{2}-(1-\epsilon) T\right]
\\ & =P\left[X-
(1-\epsilon) T \leqslant -\frac{T}{2}\left(1-2\epsilon\right)]\right]
\\ &=P\left[\sum_{i=1}^{\mathrm{T}} x_i-
\sum_{i=1}^{\mathrm{T}}\mathbb{E}(x_i) \leqslant -\frac{T}{2}\left(1-2\epsilon\right)]\right]
\\ &=P\left[\frac{1}{\mathrm{T}}\sum_{i=1}^{\mathrm{T}} x_i-\frac{1}{\mathrm{T}}
\sum_{i=1}^{\mathrm{T}}\mathbb{E}(x_i) \leqslant -\frac{1}{2}\left(1-2\epsilon\right)]\right]
\end{aligned}
$$

根据==Hoeffding不等式==知

$$
P\left(\frac{1}{m} \sum_{i=1}^{m} x_{i}-\frac{1}{m} \sum_{i=1}^{m} \mathbb{E}\left(x_{i}\right) \leqslant -\delta\right) \leqslant \exp \left(-2 m \delta^{2}\right)
$$

令$\delta=\frac {(1-2\epsilon)}{2},m=T$得

$$
\begin{aligned}
P(H(\boldsymbol{x}) \neq f(\boldsymbol{x})) &=\sum_{k=0}^{\lfloor T / 2\rfloor} \left( \begin{array}{c}{T} \\ {k}\end{array}\right)(1-\epsilon)^{k} \epsilon^{T-k} \\ & \leqslant \exp \left(-\frac{1}{2} T(1-2 \epsilon)^{2}\right)
\end{aligned}
$$

然而，在现实任务中**个体学习器是为解决同一个问题训练出来的，它们显然不可能相互独立！** 事实上，个体学习器的“准确性”和“多样性”本身就存在冲突。一般的，准确性很高之后，要增加多样性就需牺牲准确性。**事实上，如何产生并结合“好而不同”的个体学习器，恰是集成学习研究的核心**。






标准线性回归中通过最小二乘法进行参数估计，


$$
\begin{aligned}
\hat{\boldsymbol{w}}^{*}&=\underset{\hat{\boldsymbol{w}}}{\arg \min } \sum_{i=1}^{m}\left(y_{i}-\hat{\boldsymbol{w}}^\mathrm{T}\hat{\boldsymbol{x}}_{i}\right)^{2} 
\end{aligned}
\tag{1}
$$

当$\mathbf{X}^\mathrm{T}\mathbf{X}$为可逆矩阵时，令$\cfrac{\partial E_{\hat{\boldsymbol w}}}{\partial \hat{\boldsymbol w}}=0$，可得$\hat{\boldsymbol w}$最优解的闭式解，如下：

$$
\hat{\boldsymbol{w}}^{*}=(\mathbf{X}^\mathrm{T}\mathbf{X})^{-1}\mathbf{X}^\mathrm{T}y
\tag{2}
$$

然而，现实任务中$X^TX$往往不是满秩矩阵。为得到有效解，岭回归在矩阵$X^TX$对角线元素上加一个小的常数值$\lambda$，

$$
\hat{\boldsymbol{w}}^{*}_{ridge}=(\mathbf{X}^\mathrm{T}\mathbf{X}+\lambda I_n)^{-1}\mathbf{X}^\mathrm{T}y
\tag{3}
$$

其中，$I_n$是单位矩阵；$\lambda$为岭系数。

相应地，代价函数在原有残差平方和的基础上添加了对系数值的惩罚，参数估计的目标改为:

$$
\begin{aligned}
\hat{\boldsymbol{w}}^{*}_{ridge}&=\underset{\hat{\boldsymbol{w}}}{\arg \min } \sum_{i=1}^{m}\left(y_{i}-\hat{\boldsymbol{w}}^\mathrm{T}\hat{\boldsymbol{x}}_{i}\right)^{2}+\lambda \sum_{i=0}^{n} w_i^2 \\
&=\underset{\hat{\boldsymbol{w}}}{\arg \min } ||y-\hat{\boldsymbol{w}}^\mathrm{T}\hat{\boldsymbol{x}}_{i}||+\lambda ||w||

\end{aligned}
\tag{4}
$$


## 参考资料
1. https://blog.csdn.net/weixin_44225602/article/details/112912067

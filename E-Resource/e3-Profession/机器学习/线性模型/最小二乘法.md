## 前期知识

#### 均方误差

**均方误差**亦称**平方损失(Square loss)**,对应欧式距离(Euclidean distance)，具有非常好的几何意义。


**计算公式如下：**

$$
\begin{align}  
(w^*, b^*) &= \arg \min_{(w, b)} \sum_{i=1}^m \left( f(x_i) - y_i \right)^2 \\ 
&= \arg \min_{(w, b)} \sum_{i=1}^m \left( y_i - w x_i - b \right)^2 \end{align} 
\tag{2}
$$

## 定义

基于**均方误差最小化**来进行模型求解的方法称为**最小二乘法(Ordinary Least Squares, OLS)**。

## 多重共线性问题

**普通最小二乘法的系数估计依赖于特征的独立性**。当特征相关时，设计矩阵的列具有近似线性相关性，设计矩阵变得接近奇异。这种情况下，最小二乘法估计的系数会对数据中的微小变化高度敏感，从而导致估计值的方差增大。换句话说，模型对噪声的影响变得更加敏感，结果也会变得不可靠。

> [!info]+ 设计矩阵
> **设计矩阵（Design Matrix）** 是统计建模中用来表示自变量（特征变量）的矩阵。它是回归模型、线性模型等模型中用来表示样本数据的矩阵。设计矩阵中，每一行代表一个样本，每一列代表一个特征变量。

### 解决办法

###### 1. 去除高相关特征

通过检查特征之间的相关系数矩阵或方差膨胀因子（VIF）来识别并去除高相关的特征。

###### 2. 正则化方法

使用岭回归（Ridge）或套索回归（Lasso）等正则化方法，可以在模型中增加惩罚项，减小多重共线性的影响。

###### 3．主成分分析（PCA）

可以将特征投影到较低维度的空间，以减少特征之间的相关性。








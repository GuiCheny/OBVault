# 深度学习环境搭建


#### CPU选择
CPU非常重要！尽管CPU并不直接参与深度学习模型计算，但CPU需要**提供大于模型训练吞吐的数据处理能力**。我们通常为每块GPU分配固定数量的CPU逻辑核心。理想情况下，模型计算吞吐随GPU数量线性增长，单GPU的合理CPU逻辑核心数分配可以直接线性扩展到多GPU上。
#### GPU选择
按照GPU架构大致分为五类：
1. NVIDIA Pascal架构的GPU，如TitanXp，GTX 10系列等。 这类GPU缺乏低精度的硬件加速能力，但却具备中等的单精度算力。由于价格便宜，适合用来练习训练小模型(如Cifar10)或调试模型代码。
2. NVIDIA Volta/Turing架构的GPU，如GTX 20系列, Tesla V100等。 这类GPU搭载专为低精度(int8/float16)计算加速的TensorCore, 但单精度算力相较于上代提升不大。我们建议在实例上启用深度学习框架的混合精度训练来加速模型计算。 相较于单精度训练，混合精度训练通常能够提供2倍以上的训练加速。
3. NVIDIA Ampere架构的GPU，如GTX 30系列，Tesla A40/A100等。 这类GPU搭载第三代TensorCore。相较于前一代，支持了TensorFloat32格式，可直接加速单精度训练 (PyTorch已默认开启)。但我们仍建议使用超高算力的float16半精度训练模型，可获得比上一代GPU更显著的性能提升。
4. 寒武纪 MLU 200系列加速卡。 暂不支持模型训练。使用该系列加速卡进行模型推理需要量化为int8进行计算。 并且需要安装适配寒武纪MLU的深度学习框架。
5. 华为 Ascend 系列加速卡。 支持模型训练及推理。但需安装MindSpore框架进行计算。
GPU的数量选择与训练任务有关。一般我们认为模型的一次训练应当在24小时内完成，这样隔天就能训练改进之后的模型。以下是选择多GPU的一些建议：
- 1块GPU。适合一些数据集较小的训练任务，如Pascal VOC等。
- 2块GPU。同单块GPU，但是你可以一次跑两组参数或者把Batchsize扩大。
- 4块GPU。适合一些中等数据集的训练任务，如MS COCO等。
- 8块GPU。经典永流传的配置！适合各种训练任务，也非常方便复现论文结果。
  

#### 容器实例
容器实例是使用Docker技术进行资源划分与隔离的Container，拥有相比虚机实例性能损失少，效率高等优点。




##### 实例迁移





##### Conda创建虚拟环境
```
# 比如构建一个虚拟环境名为：my-env，Python版本为3.7
conda create -n my-env python=3.7    

# 更新bashrc中的环境变量
conda init bash && source /root/.bashrc

# 切换到创建的虚拟环境：my-env
conda activate my-env

# 验证
python
```

##### Python依赖安装

```
# 使用pip，举例
pip install opencv-python scipy numpy Pillow

# 使用conda，举例
conda install numpy

# 如果不确定包名，通过搜索来查找
pip search xxxx
conda search xxxx

如果在用pip时不知道某个依赖有什么版本号，那么以下trick可以查看：随便写一个版本号，pip会报错出所有可安装的版本号
$ pip install xxx=9.9
```

##### 深度学习框架安装
```
# PyTorch：从https://pytorch.org/get-started/previous-versions/找到合适的版本。比如：
conda install pytorch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 cudatoolkit=11.3 -c pytorch -c conda-forge

# TensorFlow: 从https://www.tensorflow.org/install/pip找到对应版本链接。比如：
pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.6.0-cp38-cp38-manylinux2010_x86_64.whl
```

### 镜像使用

#### 保存镜像

#### 加载镜像

#### 共享镜像



### Jupyterlab

学会使用...

### SSH远程连接

推荐使用XShell.

#### SSH登录

开机实例后，找到SSH登录指令.在您的本地终端中输入该命令，输入密码进行登录.

#### 免密登录

设置密钥登录.



# 深度学习

## 环境搭建与配置

### 本地
CUDA toolkit
CUDnn 

conda init bash && source /root/.bashrc  


执行上述代码后，Jupyter Notebook会显示出sum()函数的帮助信息，包括函数的参数列表、返回值、作用等。
1. 在函数名后面加问号，然后执行。例如，如果你想查看abs函数的用法，只需在代码单元中输入abs?并执行。这会在当前单元下方展开并显示该函数的详细信息，包括参数、返回值、描述等。
2. ？？
以上就是在Jupyter Notebook中查看函数用法的方法，希望对你有所帮助。



ssh root@region-42.seetacloud.com 48855 
BRqIwwm7wmQN




**pycharm配置conda环境**
D:\anaconda3\Scripts\conda.exe
下拉目录中就可以找到





GCC是GNU Compiler Collection的缩写，是一个开源的编译器集合，支持多种编程语言，如C、C++、Ada、Fortran等。它可以在多种平台上使用，并且是Linux和许多其他操作系统中默认的C和C++编译器。

MinGW（Minimalist GNU for Windows）是一个Windows平台上的开发工具集，它提供了一套GNU工具链，包括GCC编译器、GNU工具和一些库，用于在Windows上开发和编译C和C++程序。MinGW的目标是为Windows提供一个轻量级、最小化的GNU开发环境，它允许开发人员在Windows上使用GCC编译器来编译和运行他们的代码，同时也能方便地使用GNU工具和库。

简而言之，GCC是一个跨平台的编译器集合，而MinGW是基于GCC的一个特定于Windows平台的开发工具集。



# 深度学习环境配置

## 开发软件
### VsCode
安装python插件
Ctrl+Shift+P打开命令面板
Python:为项目选择解释器
Python:创建终端

## 环境配置
### 创建Conda虚拟环境
1. 构建虚拟环境：conda create -n my-env python=3.7    
2. 更新bashrc环境变量：conda init bash && source /root/.bashrc
3. 切换到创建的虚拟环境：conda activate my-env
4. 运行conda init，您可能需要关闭并重新启动shell

conda生成requirements.txt：conda list --export > requirements.txt
conda install --file requirements.txt

### 删除Conda虚拟环境
conda deactivate          # 退出当前(tf)环境到base环境
conda remove -n tf --all  # 清除tf环境
### 删除安装包和缓存
conda clean -y --all

### 安装CUDA/cuDNN
#### 方法一:使用conda安装
- conda install cudatoolkit == xx.xx
- conda install cudnn == xx.xx

#### 方法二:安装包安装


### 安装其他框架
1. Pytorch:https://pytorch.org/get-started/previous-versions/
2. TensorFlow:https://www.tensorflow.org/install/pip
### python依赖安装
- pip/pip3
- conda
不确定包名`pip search xxxx`或`conda search xxxx`
### 系统依赖安装
以安装Zip为例:
apt-get update
apt-get install -y zip
如果不知道包名
apt-get update    
apt-cache search xxxxx
### 安装cuda


###  远程服务器（Linux）
#### Vscode远程开发
1.本地VSCode安装Remote-SSH插件 
2.SSH连接并登录远端服务器
#### 资源上传下载
XShell
XFTP









![alt text](image.png)